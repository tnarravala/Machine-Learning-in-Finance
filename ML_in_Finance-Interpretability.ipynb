{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML_in_Finance-Interpretability.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"_kFoQyUpUAGb","colab":{},"executionInfo":{"status":"ok","timestamp":1600729404298,"user_tz":300,"elapsed":340,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["# ML_in_Finance-Interpretability\n","# Author: Matthew Dixon\n","# Version: 1.0 (08.09.2019)\n","# License: MIT\n","# Email: matthew.dixon@iit.edu\n","# Notes: tested on Mac OS X with Python 3.6.9 and the following packages:\n","# numpy=1.18.1, keras=2.3.1, tensorflow=2.0.0, statsmodels=0.10.1, scikit-learn=0.22.1\n","# Citation: Please cite the following reference if this notebook is used for research purposes:\n","# Dixon M.F., I. Halperin and P. Bilokon, Machine Learning in Finance: From Theory to Practice, Springer Graduate textbook Series, 2020. "],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UudbSI59UAGm"},"source":["# Overview\n","The purpose of this notebook is to illustrate a neural network interpretability method which is compatible with linear regression. \n","\n","In linear regression, provided the independent variables are scaled, one can view the regression coefficients as a measure of importance of the variables. Equivalently, the dependent variable can be differentiated w.r.t. the inputs to give the coefficient. \n","\n","Similarly, the derivatives of the network w.r.t. the inputs are a non-linear generalization of interpretability in linear regression. Moreover, we should expect the neural network gradients to approximate the linear regression coefficients when the data is generated by a linear regression model. \n","\n","Various simple experimental tests, corresponding to Section 3 of Chpt 5, are performed to illustrate the properties of network interpretability."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zfd1onEAUAGn","colab":{},"executionInfo":{"status":"ok","timestamp":1600729405908,"user_tz":300,"elapsed":347,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.callbacks import EarlyStopping\n","from keras.wrappers.scikit_learn import KerasRegressor\n","import statsmodels.api as sm\n","import sklearn"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3zwrQkfYUAGy"},"source":["## Simple Data Generation Process (DGP)\n","\n","\n","Let us generate data from the following linear regression model\n","\n","$Y=X_1+X_2 + \\epsilon~, ~~X_1, X_2 \\sim N(0,1)~, ~~\\epsilon \\sim N(0,1)$"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"diSrymSRUAGz","colab":{},"executionInfo":{"status":"ok","timestamp":1600729407878,"user_tz":300,"elapsed":393,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["M = 5000 # Number of samples\n","np.random.seed(7) # Set NumPy's random seed for reproducibility\n","X = np.zeros(shape=(M, 2))\n","X[:int(M/2), 0] = np.random.randn(int(M/2))\n","X[:int(M/2), 1] = np.random.randn(int(M/2))\n","\n","# Use antithetic sampling to reduce the bias in the mean\n","X[int(M/2):, 0] = -X[:int(M/2), 0]\n","X[int(M/2):, 1] = -X[:int(M/2), 1]\n","\n","eps = np.zeros(shape=(M,1))\n","eps[:int(M/2)] = np.random.randn(int(M/2), 1)\n","eps[int(M/2):] = -eps[:int(M/2)]\n","Y = X[:, 0] + X[:, 1] + eps.flatten()"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kx6JfSujUAHC"},"source":["## Use ordinary least squares to fit a linear model to the data\n","For a baseline, let us compare the neural network with OLS regression. \n","\n","We fit statsmodels' OLS model to the data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LJTP5gc1UAHD","colab":{},"executionInfo":{"status":"ok","timestamp":1600729409570,"user_tz":300,"elapsed":413,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["ols_results = sm.OLS(Y, sm.add_constant(X)).fit()"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G_rRGtlv22Nx","colab_type":"text"},"source":["For each input, get the predicted $Y$ value according to the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qqS2vAz_UAHL","colab":{},"executionInfo":{"status":"ok","timestamp":1600729411656,"user_tz":300,"elapsed":376,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["y_ols = ols_results.predict(sm.add_constant(X))"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T21yEMaK22Nz","colab_type":"text"},"source":["View characteristics of the resulting model. You should observe that the intercept is close to zero and the other coefficients are close to one."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i8fHdPH3UAHQ","colab":{"base_uri":"https://localhost:8080/","height":465},"executionInfo":{"status":"ok","timestamp":1600729413430,"user_tz":300,"elapsed":371,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}},"outputId":"4cbfcb7b-4cdc-4cc3-eda1-dd72f2e8246e"},"source":["ols_results.summary()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<table class=\"simpletable\">\n","<caption>OLS Regression Results</caption>\n","<tr>\n","  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.678</td> \n","</tr>\n","<tr>\n","  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.677</td> \n","</tr>\n","<tr>\n","  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5249.</td> \n","</tr>\n","<tr>\n","  <th>Date:</th>             <td>Mon, 21 Sep 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n","</tr>\n","<tr>\n","  <th>Time:</th>                 <td>23:03:33</td>     <th>  Log-Likelihood:    </th> <td> -7020.4</td> \n","</tr>\n","<tr>\n","  <th>No. Observations:</th>      <td>  5000</td>      <th>  AIC:               </th> <td>1.405e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Residuals:</th>          <td>  4997</td>      <th>  BIC:               </th> <td>1.407e+04</td>\n","</tr>\n","<tr>\n","  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n","</tr>\n","<tr>\n","  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n","</tr>\n","<tr>\n","  <th>const</th> <td>-6.939e-18</td> <td>    0.014</td> <td>-4.98e-16</td> <td> 1.000</td> <td>   -0.027</td> <td>    0.027</td>\n","</tr>\n","<tr>\n","  <th>x1</th>    <td>    0.9858</td> <td>    0.014</td> <td>   70.409</td> <td> 0.000</td> <td>    0.958</td> <td>    1.013</td>\n","</tr>\n","<tr>\n","  <th>x2</th>    <td>    1.0190</td> <td>    0.014</td> <td>   72.695</td> <td> 0.000</td> <td>    0.992</td> <td>    1.047</td>\n","</tr>\n","</table>\n","<table class=\"simpletable\">\n","<tr>\n","  <th>Omnibus:</th>       <td> 0.800</td> <th>  Durbin-Watson:     </th> <td>   1.941</td>\n","</tr>\n","<tr>\n","  <th>Prob(Omnibus):</th> <td> 0.670</td> <th>  Jarque-Bera (JB):  </th> <td>   0.750</td>\n","</tr>\n","<tr>\n","  <th>Skew:</th>          <td>-0.000</td> <th>  Prob(JB):          </th> <td>   0.687</td>\n","</tr>\n","<tr>\n","  <th>Kurtosis:</th>      <td> 3.060</td> <th>  Cond. No.          </th> <td>    1.02</td>\n","</tr>\n","</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."],"text/plain":["<class 'statsmodels.iolib.summary.Summary'>\n","\"\"\"\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:                      y   R-squared:                       0.678\n","Model:                            OLS   Adj. R-squared:                  0.677\n","Method:                 Least Squares   F-statistic:                     5249.\n","Date:                Mon, 21 Sep 2020   Prob (F-statistic):               0.00\n","Time:                        23:03:33   Log-Likelihood:                -7020.4\n","No. Observations:                5000   AIC:                         1.405e+04\n","Df Residuals:                    4997   BIC:                         1.407e+04\n","Df Model:                           2                                         \n","Covariance Type:            nonrobust                                         \n","==============================================================================\n","                 coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------\n","const      -6.939e-18      0.014  -4.98e-16      1.000      -0.027       0.027\n","x1             0.9858      0.014     70.409      0.000       0.958       1.013\n","x2             1.0190      0.014     72.695      0.000       0.992       1.047\n","==============================================================================\n","Omnibus:                        0.800   Durbin-Watson:                   1.941\n","Prob(Omnibus):                  0.670   Jarque-Bera (JB):                0.750\n","Skew:                          -0.000   Prob(JB):                        0.687\n","Kurtosis:                       3.060   Cond. No.                         1.02\n","==============================================================================\n","\n","Warnings:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","\"\"\""]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"m_M_l4RFUAHV"},"source":["## Compare with a feedforward NN with no hidden layers\n","\n","Recall that the feedforward network with no hidden layers or activation function is a linear regression model.\n","\n","Create a build function for the linear perceptron, which transforms the inputs directly to a single output"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gK7cKS-fUAHW","colab":{},"executionInfo":{"status":"ok","timestamp":1600729415386,"user_tz":300,"elapsed":381,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["def linear_NN0_model(l1_reg=0.0):    \n","    model = Sequential()\n","    model.add(Dense(1, input_dim=2, kernel_initializer='normal'))\n","    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n","    return model"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R3lGC4e522N7","colab_type":"text"},"source":["An early stopping callback to terminate training once the weights appear to have converged to an optimum. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FVNCG9q_UAHc","colab":{},"executionInfo":{"status":"ok","timestamp":1600729417058,"user_tz":300,"elapsed":338,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=10)"],"execution_count":19,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sNL6xMt322N-","colab_type":"text"},"source":["Passing the build function for our model and training parameters to the `KerasRegressor` constructor to create a Scikit-learn-compatible regression model. This allows you to take advantage of the library's built-in tools and estimator methods, and to incorporate it into Scikit-learn pipelines. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hlK793fFUAHh","colab":{},"executionInfo":{"status":"ok","timestamp":1600729418840,"user_tz":300,"elapsed":362,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["lm = KerasRegressor(build_fn=linear_NN0_model, epochs=40, batch_size=10, verbose=1, callbacks=[es])"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Bkr_dgD22OA","colab_type":"text"},"source":["Train the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2KDwpplKUAHm","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600729432053,"user_tz":300,"elapsed":11509,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}},"outputId":"00a82b99-3ec2-4f44-ed70-5b9ca6402613"},"source":["lm.fit(X, Y)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Epoch 1/40\n","500/500 [==============================] - 0s 752us/step - loss: 2.2519 - mae: 1.2013 - mse: 2.2519\n","Epoch 2/40\n","500/500 [==============================] - 0s 737us/step - loss: 1.4090 - mae: 0.9537 - mse: 1.4090\n","Epoch 3/40\n","500/500 [==============================] - 0s 738us/step - loss: 1.0856 - mae: 0.8327 - mse: 1.0856\n","Epoch 4/40\n","500/500 [==============================] - 0s 779us/step - loss: 0.9926 - mae: 0.7957 - mse: 0.9926\n","Epoch 5/40\n","500/500 [==============================] - 0s 774us/step - loss: 0.9741 - mae: 0.7877 - mse: 0.9741\n","Epoch 6/40\n","500/500 [==============================] - 0s 737us/step - loss: 0.9717 - mae: 0.7869 - mse: 0.9717\n","Epoch 7/40\n","500/500 [==============================] - 0s 791us/step - loss: 0.9712 - mae: 0.7866 - mse: 0.9712\n","Epoch 8/40\n","500/500 [==============================] - 0s 751us/step - loss: 0.9715 - mae: 0.7868 - mse: 0.9715\n","Epoch 9/40\n","500/500 [==============================] - 0s 822us/step - loss: 0.9713 - mae: 0.7866 - mse: 0.9713\n","Epoch 10/40\n","500/500 [==============================] - 0s 801us/step - loss: 0.9715 - mae: 0.7868 - mse: 0.9715\n","Epoch 11/40\n","500/500 [==============================] - 0s 805us/step - loss: 0.9714 - mae: 0.7868 - mse: 0.9714\n","Epoch 12/40\n","500/500 [==============================] - 0s 806us/step - loss: 0.9714 - mae: 0.7868 - mse: 0.9714\n","Epoch 13/40\n","500/500 [==============================] - 0s 772us/step - loss: 0.9715 - mae: 0.7866 - mse: 0.9715\n","Epoch 14/40\n","500/500 [==============================] - 0s 739us/step - loss: 0.9712 - mae: 0.7865 - mse: 0.9712\n","Epoch 15/40\n","500/500 [==============================] - 0s 745us/step - loss: 0.9714 - mae: 0.7867 - mse: 0.9714\n","Epoch 16/40\n","500/500 [==============================] - 0s 737us/step - loss: 0.9716 - mae: 0.7869 - mse: 0.9716\n","Epoch 17/40\n","500/500 [==============================] - 0s 770us/step - loss: 0.9715 - mae: 0.7867 - mse: 0.9715\n","Epoch 18/40\n","500/500 [==============================] - 0s 787us/step - loss: 0.9711 - mae: 0.7867 - mse: 0.9711\n","Epoch 19/40\n","500/500 [==============================] - 0s 739us/step - loss: 0.9715 - mae: 0.7869 - mse: 0.9715\n","Epoch 20/40\n","500/500 [==============================] - 0s 764us/step - loss: 0.9715 - mae: 0.7866 - mse: 0.9715\n","Epoch 21/40\n","500/500 [==============================] - 0s 808us/step - loss: 0.9715 - mae: 0.7869 - mse: 0.9715\n","Epoch 22/40\n","500/500 [==============================] - 0s 765us/step - loss: 0.9715 - mae: 0.7868 - mse: 0.9715\n","Epoch 23/40\n","500/500 [==============================] - 0s 747us/step - loss: 0.9716 - mae: 0.7870 - mse: 0.9716\n","Epoch 24/40\n","500/500 [==============================] - 0s 769us/step - loss: 0.9713 - mae: 0.7867 - mse: 0.9713\n","Epoch 25/40\n","500/500 [==============================] - 0s 773us/step - loss: 0.9714 - mae: 0.7868 - mse: 0.9714\n","Epoch 26/40\n","500/500 [==============================] - 0s 767us/step - loss: 0.9716 - mae: 0.7867 - mse: 0.9716\n","Epoch 27/40\n","500/500 [==============================] - 0s 785us/step - loss: 0.9716 - mae: 0.7868 - mse: 0.9716\n","Epoch 28/40\n","500/500 [==============================] - 0s 815us/step - loss: 0.9712 - mae: 0.7867 - mse: 0.9712\n","Epoch 00028: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f1804ba7668>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iokoBVzTUAHs"},"source":["### Check that the weights are close to one\n","The weights should be close to unity. The bias term is the second entry and should be close to zero."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ErrGUmQ7UAHt","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1600729436236,"user_tz":300,"elapsed":320,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}},"outputId":"b55dbae3-5064-4fb2-8657-221c2d8bdddb"},"source":["print(\"weights: \" + str(lm.model.layers[0].get_weights()[0]))\n","print(\"bias: \" + str(lm.model.layers[0].get_weights()[1]))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["weights: [[0.98217595]\n"," [1.0337954 ]]\n","bias: [-0.00366889]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XeY2UlfbUAHz"},"source":["## Compare with a FFW Neural Network with one hidden layer (unactivated)\n"]},{"cell_type":"markdown","metadata":{"id":"jjonGh4j22OG","colab_type":"text"},"source":["This time we create a neural network with a hidden layer with 10 units."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EEz8Yig7UAHz","colab":{},"executionInfo":{"status":"ok","timestamp":1600729439264,"user_tz":300,"elapsed":341,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["n = 10 # number of hidden units"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9DXvB6wUUAH4","colab":{},"executionInfo":{"status":"ok","timestamp":1600729440255,"user_tz":300,"elapsed":304,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["def linear_NN1_model(l1_reg=0.0):    \n","    model = Sequential()\n","    model.add(Dense(n, input_dim=2, kernel_initializer='normal')) \n","    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n","    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n","    return model"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cX3ZHz0tUAH-","colab":{},"executionInfo":{"status":"ok","timestamp":1600729441255,"user_tz":300,"elapsed":318,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["lm = KerasRegressor(build_fn=linear_NN1_model, epochs=50, batch_size=10, verbose=1, callbacks=[es])"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zq6A4WMzUAIC","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"status":"ok","timestamp":1600729449436,"user_tz":300,"elapsed":7515,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}},"outputId":"3870514b-68d4-4a0c-ff26-5effe924a441"},"source":["lm.fit(X, Y)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","500/500 [==============================] - 0s 821us/step - loss: 1.5718 - mae: 0.9785 - mse: 1.5718\n","Epoch 2/50\n","500/500 [==============================] - 0s 856us/step - loss: 0.9733 - mae: 0.7873 - mse: 0.9733\n","Epoch 3/50\n","500/500 [==============================] - 0s 831us/step - loss: 0.9731 - mae: 0.7873 - mse: 0.9731\n","Epoch 4/50\n","500/500 [==============================] - 0s 840us/step - loss: 0.9738 - mae: 0.7876 - mse: 0.9738\n","Epoch 5/50\n","500/500 [==============================] - 0s 827us/step - loss: 0.9729 - mae: 0.7871 - mse: 0.9729\n","Epoch 6/50\n","500/500 [==============================] - 0s 837us/step - loss: 0.9729 - mae: 0.7870 - mse: 0.9729\n","Epoch 7/50\n","500/500 [==============================] - 0s 831us/step - loss: 0.9732 - mae: 0.7874 - mse: 0.9732\n","Epoch 8/50\n","500/500 [==============================] - 0s 846us/step - loss: 0.9730 - mae: 0.7876 - mse: 0.9730\n","Epoch 9/50\n","500/500 [==============================] - 0s 884us/step - loss: 0.9738 - mae: 0.7887 - mse: 0.9738\n","Epoch 10/50\n","500/500 [==============================] - 0s 946us/step - loss: 0.9738 - mae: 0.7881 - mse: 0.9738\n","Epoch 11/50\n","500/500 [==============================] - 0s 854us/step - loss: 0.9740 - mae: 0.7872 - mse: 0.9740\n","Epoch 12/50\n","500/500 [==============================] - 0s 802us/step - loss: 0.9735 - mae: 0.7880 - mse: 0.9735\n","Epoch 13/50\n","500/500 [==============================] - 0s 858us/step - loss: 0.9737 - mae: 0.7875 - mse: 0.9737\n","Epoch 14/50\n","500/500 [==============================] - 0s 890us/step - loss: 0.9738 - mae: 0.7878 - mse: 0.9738\n","Epoch 15/50\n","500/500 [==============================] - 0s 845us/step - loss: 0.9737 - mae: 0.7878 - mse: 0.9737\n","Epoch 16/50\n","500/500 [==============================] - 0s 793us/step - loss: 0.9741 - mae: 0.7879 - mse: 0.9741\n","Epoch 00016: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f1804c5f9e8>"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kcwH9k3tUAIF","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1600729452128,"user_tz":300,"elapsed":339,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}},"outputId":"3c9534e9-42c8-4807-9e9f-7c11c1b08ee2"},"source":["W1 = lm.model.get_weights()[0]\n","b1 = lm.model.get_weights()[1]\n","W2 = lm.model.get_weights()[2]\n","b2 = lm.model.get_weights()[3]\n","print(W1, W2)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["[[-0.3773278  -0.2236989  -0.35481596 -0.34812185  0.3253199   0.26338968\n","   0.30855018  0.38172016  0.39396024  0.22428878]\n"," [-0.26117954 -0.36914834 -0.35925072 -0.30433056  0.34873417  0.34487224\n","   0.25501597  0.40840706  0.3272932   0.34817845]] [[-0.28649876]\n"," [-0.33347732]\n"," [-0.2902729 ]\n"," [-0.32563964]\n"," [ 0.30829367]\n"," [ 0.3128368 ]\n"," [ 0.32633594]\n"," [ 0.27538082]\n"," [ 0.30303347]\n"," [ 0.31902447]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pgdJ8GHBUAIJ"},"source":["### Check that the coefficients are close to one and the intercept is close to zero"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4QUD6mBTUAIK","colab":{},"executionInfo":{"status":"ok","timestamp":1600729454763,"user_tz":300,"elapsed":324,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["beta_0 = np.dot(np.transpose(W2), b1) + b2\n","beta_1 = np.dot(np.transpose(W2), W1[0])\n","beta_2 = np.dot(np.transpose(W2), W1[1])"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GUE_8PjFUAIO","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600729455819,"user_tz":300,"elapsed":324,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}},"outputId":"adc290c4-4f53-4923-e184-2e241833b8ee"},"source":["print(beta_0, beta_1, beta_2)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["[0.00052501] [0.9784964] [1.0226609]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YLXKtdM8UAIS"},"source":["## Compare with a feedforward NN with one hidden layer ($tanh$ activated)"]},{"cell_type":"markdown","metadata":{"id":"rjHjAiZG22OV","colab_type":"text"},"source":["Finally, we create another model with a 10 unit hidden layer, this time with a $tanh$ activation function."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zwVeJX1KUAIU","colab":{},"executionInfo":{"status":"ok","timestamp":1600729459778,"user_tz":300,"elapsed":673,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["# number of hidden neurons\n","n = 10"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QTrU8L9_UAIY","colab":{},"executionInfo":{"status":"ok","timestamp":1600729460832,"user_tz":300,"elapsed":357,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["# with non-linear activation\n","def linear_NN1_model_act(l1_reg=0.0):    \n","    model = Sequential()\n","    model.add(Dense(n, input_dim=2, kernel_initializer='normal', activation='tanh'))\n","    model.add(Dense(1, kernel_initializer='normal')) \n","    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse'])\n","    return model"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ga1tsGQAUAIc","colab":{},"executionInfo":{"status":"ok","timestamp":1600729462246,"user_tz":300,"elapsed":644,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["lm = KerasRegressor(build_fn=linear_NN1_model_act, epochs=100, batch_size=10, verbose=1, callbacks=[es])"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aV-RH4E822Oc","colab_type":"text"},"source":["Train the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YZwN89X8UAIg","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600729495903,"user_tz":300,"elapsed":32149,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}},"outputId":"b6897441-751e-4e5f-da32-79b4038618c0"},"source":["lm.fit(X, Y)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","500/500 [==============================] - 0s 822us/step - loss: 1.6636 - mae: 1.0117 - mse: 1.6636\n","Epoch 2/100\n","500/500 [==============================] - 0s 830us/step - loss: 0.9921 - mae: 0.7957 - mse: 0.9921\n","Epoch 3/100\n","500/500 [==============================] - 0s 815us/step - loss: 0.9905 - mae: 0.7954 - mse: 0.9905\n","Epoch 4/100\n","500/500 [==============================] - 0s 849us/step - loss: 0.9882 - mae: 0.7946 - mse: 0.9882\n","Epoch 5/100\n","500/500 [==============================] - 0s 839us/step - loss: 0.9870 - mae: 0.7937 - mse: 0.9870\n","Epoch 6/100\n","500/500 [==============================] - 0s 866us/step - loss: 0.9854 - mae: 0.7929 - mse: 0.9854\n","Epoch 7/100\n","500/500 [==============================] - 0s 814us/step - loss: 0.9834 - mae: 0.7921 - mse: 0.9834\n","Epoch 8/100\n","500/500 [==============================] - 0s 813us/step - loss: 0.9830 - mae: 0.7927 - mse: 0.9830\n","Epoch 9/100\n","500/500 [==============================] - 0s 851us/step - loss: 0.9822 - mae: 0.7920 - mse: 0.9822\n","Epoch 10/100\n","500/500 [==============================] - 0s 819us/step - loss: 0.9824 - mae: 0.7917 - mse: 0.9824\n","Epoch 11/100\n","500/500 [==============================] - 0s 862us/step - loss: 0.9812 - mae: 0.7916 - mse: 0.9812\n","Epoch 12/100\n","500/500 [==============================] - 0s 802us/step - loss: 0.9801 - mae: 0.7907 - mse: 0.9801\n","Epoch 13/100\n","500/500 [==============================] - 0s 851us/step - loss: 0.9794 - mae: 0.7909 - mse: 0.9794\n","Epoch 14/100\n","500/500 [==============================] - 0s 824us/step - loss: 0.9796 - mae: 0.7906 - mse: 0.9796\n","Epoch 15/100\n","500/500 [==============================] - 0s 838us/step - loss: 0.9787 - mae: 0.7889 - mse: 0.9787\n","Epoch 16/100\n","500/500 [==============================] - 0s 833us/step - loss: 0.9790 - mae: 0.7902 - mse: 0.9790\n","Epoch 17/100\n","500/500 [==============================] - 0s 860us/step - loss: 0.9783 - mae: 0.7902 - mse: 0.9783\n","Epoch 18/100\n","500/500 [==============================] - 0s 830us/step - loss: 0.9785 - mae: 0.7906 - mse: 0.9785\n","Epoch 19/100\n","500/500 [==============================] - 0s 814us/step - loss: 0.9786 - mae: 0.7902 - mse: 0.9786\n","Epoch 20/100\n","500/500 [==============================] - 0s 815us/step - loss: 0.9768 - mae: 0.7893 - mse: 0.9768\n","Epoch 21/100\n","500/500 [==============================] - 0s 833us/step - loss: 0.9771 - mae: 0.7901 - mse: 0.9771\n","Epoch 22/100\n","500/500 [==============================] - 0s 828us/step - loss: 0.9786 - mae: 0.7915 - mse: 0.9786\n","Epoch 23/100\n","500/500 [==============================] - 0s 871us/step - loss: 0.9767 - mae: 0.7895 - mse: 0.9767\n","Epoch 24/100\n","500/500 [==============================] - 0s 905us/step - loss: 0.9771 - mae: 0.7898 - mse: 0.9771\n","Epoch 25/100\n","500/500 [==============================] - 0s 864us/step - loss: 0.9777 - mae: 0.7904 - mse: 0.9777\n","Epoch 26/100\n","500/500 [==============================] - 0s 861us/step - loss: 0.9769 - mae: 0.7897 - mse: 0.9769\n","Epoch 27/100\n","500/500 [==============================] - 0s 828us/step - loss: 0.9778 - mae: 0.7902 - mse: 0.9778\n","Epoch 28/100\n","500/500 [==============================] - 0s 875us/step - loss: 0.9780 - mae: 0.7905 - mse: 0.9780\n","Epoch 29/100\n","500/500 [==============================] - 0s 841us/step - loss: 0.9760 - mae: 0.7894 - mse: 0.9760\n","Epoch 30/100\n","500/500 [==============================] - 0s 850us/step - loss: 0.9770 - mae: 0.7897 - mse: 0.9770\n","Epoch 31/100\n","500/500 [==============================] - 0s 811us/step - loss: 0.9773 - mae: 0.7904 - mse: 0.9773\n","Epoch 32/100\n","500/500 [==============================] - 0s 852us/step - loss: 0.9769 - mae: 0.7898 - mse: 0.9769\n","Epoch 33/100\n","500/500 [==============================] - 0s 867us/step - loss: 0.9777 - mae: 0.7899 - mse: 0.9777\n","Epoch 34/100\n","500/500 [==============================] - 0s 841us/step - loss: 0.9762 - mae: 0.7893 - mse: 0.9762\n","Epoch 35/100\n","500/500 [==============================] - 0s 865us/step - loss: 0.9771 - mae: 0.7898 - mse: 0.9771\n","Epoch 36/100\n","500/500 [==============================] - 0s 870us/step - loss: 0.9776 - mae: 0.7900 - mse: 0.9776\n","Epoch 37/100\n","500/500 [==============================] - 0s 927us/step - loss: 0.9757 - mae: 0.7899 - mse: 0.9757\n","Epoch 38/100\n","500/500 [==============================] - 0s 887us/step - loss: 0.9777 - mae: 0.7892 - mse: 0.9777\n","Epoch 39/100\n","500/500 [==============================] - 0s 896us/step - loss: 0.9757 - mae: 0.7886 - mse: 0.9757\n","Epoch 40/100\n","500/500 [==============================] - 0s 847us/step - loss: 0.9768 - mae: 0.7901 - mse: 0.9768\n","Epoch 41/100\n","500/500 [==============================] - 0s 825us/step - loss: 0.9759 - mae: 0.7899 - mse: 0.9759\n","Epoch 42/100\n","500/500 [==============================] - 0s 833us/step - loss: 0.9763 - mae: 0.7896 - mse: 0.9763\n","Epoch 43/100\n","500/500 [==============================] - 0s 877us/step - loss: 0.9773 - mae: 0.7900 - mse: 0.9773\n","Epoch 44/100\n","500/500 [==============================] - 0s 843us/step - loss: 0.9758 - mae: 0.7895 - mse: 0.9758\n","Epoch 45/100\n","500/500 [==============================] - 0s 835us/step - loss: 0.9757 - mae: 0.7902 - mse: 0.9757\n","Epoch 46/100\n","500/500 [==============================] - 0s 896us/step - loss: 0.9754 - mae: 0.7895 - mse: 0.9754\n","Epoch 47/100\n","500/500 [==============================] - 0s 863us/step - loss: 0.9763 - mae: 0.7890 - mse: 0.9763\n","Epoch 48/100\n","500/500 [==============================] - 0s 825us/step - loss: 0.9765 - mae: 0.7898 - mse: 0.9765\n","Epoch 49/100\n","500/500 [==============================] - 0s 850us/step - loss: 0.9755 - mae: 0.7890 - mse: 0.9755\n","Epoch 50/100\n","500/500 [==============================] - 0s 837us/step - loss: 0.9757 - mae: 0.7894 - mse: 0.9757\n","Epoch 51/100\n","500/500 [==============================] - 0s 888us/step - loss: 0.9769 - mae: 0.7897 - mse: 0.9769\n","Epoch 52/100\n","500/500 [==============================] - 0s 884us/step - loss: 0.9752 - mae: 0.7883 - mse: 0.9752\n","Epoch 53/100\n","500/500 [==============================] - 0s 869us/step - loss: 0.9769 - mae: 0.7899 - mse: 0.9769\n","Epoch 54/100\n","500/500 [==============================] - 0s 848us/step - loss: 0.9764 - mae: 0.7897 - mse: 0.9764\n","Epoch 55/100\n","500/500 [==============================] - 0s 841us/step - loss: 0.9755 - mae: 0.7892 - mse: 0.9755\n","Epoch 56/100\n","500/500 [==============================] - 0s 937us/step - loss: 0.9764 - mae: 0.7888 - mse: 0.9764\n","Epoch 57/100\n","500/500 [==============================] - 0s 893us/step - loss: 0.9762 - mae: 0.7899 - mse: 0.9762\n","Epoch 58/100\n","500/500 [==============================] - 0s 858us/step - loss: 0.9751 - mae: 0.7885 - mse: 0.9751\n","Epoch 59/100\n","500/500 [==============================] - 0s 843us/step - loss: 0.9754 - mae: 0.7893 - mse: 0.9754\n","Epoch 60/100\n","500/500 [==============================] - 0s 863us/step - loss: 0.9761 - mae: 0.7900 - mse: 0.9761\n","Epoch 61/100\n","500/500 [==============================] - 0s 924us/step - loss: 0.9761 - mae: 0.7893 - mse: 0.9761\n","Epoch 62/100\n","500/500 [==============================] - 0s 863us/step - loss: 0.9735 - mae: 0.7882 - mse: 0.9735\n","Epoch 63/100\n","500/500 [==============================] - 0s 837us/step - loss: 0.9757 - mae: 0.7896 - mse: 0.9757\n","Epoch 64/100\n","500/500 [==============================] - 0s 856us/step - loss: 0.9760 - mae: 0.7899 - mse: 0.9760\n","Epoch 65/100\n","500/500 [==============================] - 0s 829us/step - loss: 0.9756 - mae: 0.7896 - mse: 0.9756\n","Epoch 66/100\n","500/500 [==============================] - 0s 843us/step - loss: 0.9759 - mae: 0.7891 - mse: 0.9759\n","Epoch 67/100\n","500/500 [==============================] - 0s 873us/step - loss: 0.9769 - mae: 0.7893 - mse: 0.9769\n","Epoch 68/100\n","500/500 [==============================] - 0s 849us/step - loss: 0.9749 - mae: 0.7893 - mse: 0.9749\n","Epoch 69/100\n","500/500 [==============================] - 0s 827us/step - loss: 0.9761 - mae: 0.7894 - mse: 0.9761\n","Epoch 70/100\n","500/500 [==============================] - 0s 819us/step - loss: 0.9770 - mae: 0.7891 - mse: 0.9770\n","Epoch 71/100\n","500/500 [==============================] - 0s 825us/step - loss: 0.9765 - mae: 0.7898 - mse: 0.9765\n","Epoch 72/100\n","500/500 [==============================] - 0s 855us/step - loss: 0.9753 - mae: 0.7894 - mse: 0.9753\n","Epoch 00072: early stopping\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f18073a2898>"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mU3sy8asUAIk"},"source":["### Compute the Sensitivities"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xNOwwjCfUAIk","colab":{},"executionInfo":{"status":"ok","timestamp":1600729521129,"user_tz":300,"elapsed":342,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["# Assumes that the activation function is tanh\n","def sensitivities(lm, X):\n","    \n","    W1 = lm.model.get_weights()[0]\n","    b1 = lm.model.get_weights()[1]\n","    W2 = lm.model.get_weights()[2]\n","    b2 = lm.model.get_weights()[3]\n","    \n","    \n","    M = np.shape(X)[0]\n","    p = np.shape(X)[1]\n","\n","    beta = np.array([0]*M*(p+1), dtype='float32').reshape(M,p+1)\n","    \n","    beta[:, 0] = (np.dot(np.transpose(W2), np.tanh(b1)) + b2)[0] # intercept \\beta_0= F_{W,b}(0)\n","    for i in range(M):\n"," \n","        Z1 = np.tanh(np.dot(np.transpose(W1),np.transpose(X[i,])) + b1)\n","      \n","        D = np.diag(1 - Z1**2)\n","        \n","        for j in range(p):  \n","            beta[i, j+1] = np.dot(np.transpose(W2), np.dot(D, W1[j]))\n","            \n","    return beta"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ux3ey5dfUAIn","colab":{},"executionInfo":{"status":"ok","timestamp":1600729523001,"user_tz":300,"elapsed":447,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}}},"source":["beta = sensitivities(lm, X)"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jiOcNG7CUAIr"},"source":["### Check that the intercept is close to one and the coefficients are close to one"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kWMqCNwhUAIt","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600729524954,"user_tz":300,"elapsed":307,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}},"outputId":"c2bfe7cb-0844-4d8c-8eb3-1ff90cb963aa"},"source":["print(np.mean(beta, axis=0))"],"execution_count":36,"outputs":[{"output_type":"stream","text":["[0.02807781 0.9681357  1.0832785 ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pHy9jOlEUAIw","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600729526320,"user_tz":300,"elapsed":326,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}},"outputId":"c5329b1c-fe4e-4074-bd87-2b1a4661904b"},"source":["print(np.std(beta, axis=0))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["[1.4044788e-06 6.2763922e-02 7.0253789e-02]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3RmbXWqO22Om","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":198},"executionInfo":{"status":"error","timestamp":1600729551899,"user_tz":300,"elapsed":336,"user":{"displayName":"Thejeswar Reddy Narravala","photoUrl":"","userId":"10422858166344149752"}},"outputId":"2a756d11-3aa0-48cd-ca75-bac5fa276cda"},"source":["np.histogram()"],"execution_count":38,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-4b83ae6f73c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: _histogram_dispatcher() missing 1 required positional argument: 'a'"]}]},{"cell_type":"code","metadata":{"id":"ppIMfOPt6pJ7","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}